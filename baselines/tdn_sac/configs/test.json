{
  "common":{
    "n":1,
    "gamma": 0.99
  },
  "buffer":{
    "max_buffer_size": 100
  },
  "agent":{
    "update_target_network_interval": 1,
    "target_smoothing_tau": 0.005,
    "alpha": 0.2,
    "q_network":{
      "hidden_dims": [20,20],
      "optimizer_class": "Adam",
      "learning_rate":0.001,
      "act_fn": "relu",
      "out_act_fn": "identity"
    },
    "policy_network":{
      "hidden_dims": [20,20],
      "optimizer_class": "Adam",
      "deterministic": false,
      "learning_rate":0.001,
      "act_fn": "relu",
      "out_act_fn": "identity",
      "reparameterize": true
    },
    "entropy":{
      "automatic_tuning": true,
      "learning_rate": 0.001,
      "optimizer_class": "Adam"
    }
  },
  "trainer":{
    "adaptive_config":{
      "bias_estimator": "1",
      "variance_estimator": "1",
      "value_bound":"1",
      "n_choices": [1, 2, 3, 4, 5, 8, 10, 15,20, 30, 40, 50, 100]
    },
    "max_iteration": 10,
    "num_updates_per_iteration":5,
    "num_steps_per_iteration": 5,
    "batch_size": 4,
    "max_trajectory_length":100,
    "test_interval": 1,
    "num_test_trajectories": 3,
    "save_model_interval": 1,
    "start_timestep": 1,
    "save_video_demo_interval": 1,
    "log_interval": 1,
    "update_n_interval": 1
  },
  "env":{
    "reward_scale": 10.0
  }
  
}
